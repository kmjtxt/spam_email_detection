{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "81cc93f3",
   "metadata": {},
   "source": [
    "Addressing hypothesis 1 - Words may be used for different meanings in the different contexts (spam or non-spam)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "52d5c358",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Python312\\Lib\\site-packages\\requests\\__init__.py:86: RequestsDependencyWarning: Unable to find acceptable character detection dependency (chardet or charset_normalizer).\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score\n",
    "from sklearn.pipeline import FeatureUnion, Pipeline\n",
    "from sklearn.preprocessing import FunctionTransformer\n",
    "from gensim.models import Word2Vec\n",
    "from nltk.tokenize import word_tokenize"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "bde8045d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "training dataset shape: (100737, 8)\n",
      "testing dataset shape: (25185, 8)\n"
     ]
    }
   ],
   "source": [
    "train_df = pd.read_csv(\"./data/processed/training.csv\")\n",
    "test_df = pd.read_csv(\"./data/processed/testing.csv\")\n",
    "print(f\"training dataset shape: {train_df.shape}\")\n",
    "print(f\"testing dataset shape: {test_df.shape}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1ff55602",
   "metadata": {},
   "source": [
    "Benchmark: Logistic Regression with BoW"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "d0f67414",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy:  0.983284\n",
      "Precision: 0.978607\n",
      "Recall:    0.986242\n",
      "F1 Score:  0.982409\n"
     ]
    }
   ],
   "source": [
    "# Build the pipeline: BoW + Logistic Regression\n",
    "pipeline = Pipeline([\n",
    "    (\"bow\", CountVectorizer()), # Converts text to BoW feature vectors\n",
    "    (\"classifier\", LogisticRegression(max_iter=1000))\n",
    "])\n",
    "\n",
    "# Train the model\n",
    "pipeline.fit(train_df['cleaned_body'], train_df['label'])\n",
    "\n",
    "# Predict and evaluate\n",
    "y_pred_bow_only = pipeline.predict(test_df['cleaned_body'])\n",
    "accuracy_bow_only = accuracy_score(test_df['label'], y_pred_bow_only)\n",
    "precision_bow_only = precision_score(test_df['label'], y_pred_bow_only)\n",
    "recall_bow_only = recall_score(test_df['label'], y_pred_bow_only)\n",
    "f1_bow_only = f1_score(test_df['label'], y_pred_bow_only)\n",
    "\n",
    "print(f\"Accuracy:  {accuracy_bow_only:.6f}\")\n",
    "print(f\"Precision: {precision_bow_only:.6f}\")\n",
    "print(f\"Recall:    {recall_bow_only:.6f}\")\n",
    "print(f\"F1 Score:  {f1_bow_only:.6f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c9e6c9ba",
   "metadata": {},
   "source": [
    "Alternative to test if word2vec feature is useful: Logistic Regression with BoW + word2vec"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "4c95a026",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy:  0.982728\n",
      "Precision: 0.978422\n",
      "Recall:    0.985235\n",
      "F1 Score:  0.981817\n"
     ]
    }
   ],
   "source": [
    "# Tokenize training and testing text for Word2Vec\n",
    "X_train_tokens = [word_tokenize(text) for text in train_df['tokens']]\n",
    "\n",
    "# Train Word2Vec model on training tokens only\n",
    "w2v_model = Word2Vec(sentences=X_train_tokens, vector_size=100, window=5, min_count=1)\n",
    "\n",
    "# Function to compute average Word2Vec vector for a sentence\n",
    "def get_avg_w2v_features(texts, model, vector_size):\n",
    "    features = []\n",
    "    for text in texts:\n",
    "        tokens = word_tokenize(text)\n",
    "        valid_tokens = [t for t in tokens if t in model.wv]\n",
    "        if not valid_tokens:\n",
    "            features.append(np.zeros(vector_size))\n",
    "        else:\n",
    "            vec = np.mean([model.wv[t] for t in valid_tokens], axis=0)\n",
    "            features.append(vec)\n",
    "    return np.array(features)\n",
    "\n",
    "# FunctionTransformer for Word2Vec averaging\n",
    "w2v_transformer = FunctionTransformer(\n",
    "    lambda x: get_avg_w2v_features(x, w2v_model, 100),\n",
    "    validate=False\n",
    ")\n",
    "\n",
    "# Combine TF-IDF and Word2Vec features\n",
    "combined_features = FeatureUnion([\n",
    "    (\"bow\", Pipeline([(\"bow\", CountVectorizer())])),\n",
    "    (\"w2v\", Pipeline([(\"w2v\", w2v_transformer)]))\n",
    "])\n",
    "\n",
    "# Pipeline: feature extraction + classifier\n",
    "pipeline = Pipeline([\n",
    "    (\"features\", combined_features),\n",
    "    (\"classifier\", LogisticRegression(max_iter=1000))\n",
    "])\n",
    "\n",
    "# Fit on training set and evaluate on test set\n",
    "pipeline.fit(train_df['cleaned_body'], train_df['label'])\n",
    "y_pred = pipeline.predict(test_df['cleaned_body'])\n",
    "\n",
    "accuracy = accuracy_score(test_df['label'], y_pred)\n",
    "precision = precision_score(test_df['label'], y_pred)\n",
    "recall = recall_score(test_df['label'], y_pred)\n",
    "f1 = f1_score(test_df['label'], y_pred)\n",
    "\n",
    "print(f\"Accuracy:  {accuracy:.6f}\")\n",
    "print(f\"Precision: {precision:.6f}\")\n",
    "print(f\"Recall:    {recall:.6f}\")\n",
    "print(f\"F1 Score:  {f1:.6f}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "25ac3cff",
   "metadata": {},
   "source": [
    "The benchmark model fared better in all 4 performance metrics compared to the alternative model.\n",
    "Let's take a closer look at why accounting for word semantics unexpectedly decreased model performance."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "ab671c72",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Benchmark & Alternative models disagreed on these rows, resulting in df with shape: (44, 2)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>cleaned_body</th>\n",
       "      <th>label</th>\n",
       "      <th>baseline_predict</th>\n",
       "      <th>alternative_predict</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>621</th>\n",
       "      <td>calger pastoria q q fountain valley eas delta ...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>623</th>\n",
       "      <td>url a detector from an asteroidchasing nasa pr...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1602</th>\n",
       "      <td>bill is this the david gray you are going to s...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1622</th>\n",
       "      <td>download dispatch tools for software developer...</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2026</th>\n",
       "      <td>so i tired grahams method first and got an err...</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                           cleaned_body  label  \\\n",
       "621   calger pastoria q q fountain valley eas delta ...      0   \n",
       "623   url a detector from an asteroidchasing nasa pr...      0   \n",
       "1602  bill is this the david gray you are going to s...      0   \n",
       "1622  download dispatch tools for software developer...      0   \n",
       "2026  so i tired grahams method first and got an err...      0   \n",
       "\n",
       "      baseline_predict  alternative_predict  \n",
       "621                  0                    1  \n",
       "623                  0                    1  \n",
       "1602                 0                    1  \n",
       "1622                 1                    0  \n",
       "2026                 1                    0  "
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "results_analysis_df = test_df[[\"cleaned_body\", \"label\"]]\n",
    "results_analysis_df = results_analysis_df[y_pred_bow_only != y_pred]\n",
    "print(f\"Benchmark & Alternative models disagreed on these rows, resulting in df with shape: {results_analysis_df.shape}\")\n",
    "results_analysis_df[\"baseline_predict\"] = y_pred_bow_only[y_pred_bow_only != y_pred]\n",
    "results_analysis_df[\"alternative_predict\"] = y_pred[y_pred_bow_only != y_pred]\n",
    "results_analysis_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c98a71dc",
   "metadata": {},
   "source": [
    "We will filter for the rows where the benchmark model predicted correctly but the alternative model predicted wrongly. There are 31 of such rows."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "f2c1bab0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(29, 4)"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "results_analysis_df[(results_analysis_df[\"label\"] == results_analysis_df[\"baseline_predict\"])].shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f5aeab53",
   "metadata": {},
   "source": [
    "The following 3 email content are some example instances where the **baseline model correctly identified spam** but the alternative model misidentified.\n",
    "\n",
    "We observe that these content are spam mainly because of the repeated use of words which allowed the BoW-only model which keeps a count of words to fare better. As the usage of words were not typical of spam messages, the added word2vec feature in the alternative model may have led the model away from the correct answer. This shows that the information gleaned from analyzing word semantics may be limited in identifying content that is spam not due to its meaning but spam because of other reasons. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "6983e05a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Example content 1: 'see attachment iain didnt go into detail but the council didnt give their b they dont know about the meeti patrick nodded therell be tro'\n",
      "Example content 2: 'java virtual machine instructions are represented in this chapter by entries of the form shown in figure also he limped badly with one leg i also omitted methods such as freenet napster hotmail gnutella mostly because i think they are inherently bad and would have lead to misinterpretation of my goals was there reproach to him in the quiet figure and the mild eyes in the last several years this kind of software has advanced rapidly ah for my husband for my dear lord edward the center window is an ultrawave map of the region directly behind us the password protects your web site from the possibility of someone else making changes to it receives the message that matches the given correlation identifier from a transactional queue and immediately raises an exception if no message with the specified correlation identifier currently exists in the queue pray you then conduct me to the queen a taste of blood in my mouth also have a look at the example menu the spiritual and the physical had been blended in us with a perfection that must remain incomprehensible to the matteroffact crude standardbrained youngsters of today anyway deep thought decided that dolphins were to be part of the network all i could remember was the wonderful pair of horns we had seen in the game wardens office in arusha smith ajay sirsi amir ranjbar cisco press in the use runtime library dropdown list select debug multithreaded dll starting in readonly mode can also be done with vim r if the file is opened the c runtime fstat function copies information about the file into the filestatus structure once your application has loaded a cursor it can use that cursor shape whenever it needs to an unicode editor of your choice can be used to edit and sort the files pray master barnardine awake till you are executed and sleep afterwards pray you which is the head lady he will fulfill no prophecies dead and even if he manages to avoid darkfriends and shadowspawn there are a thousand other hands ready to slay him'\n",
      "Example content 3: 'roedig hazzah youd like to great guide j cain whats inside player manage targeting email tracking'\n"
     ]
    }
   ],
   "source": [
    "actually_spam = results_analysis_df[(results_analysis_df[\"label\"] == results_analysis_df[\"baseline_predict\"]) & (results_analysis_df[\"label\"] == 1)]\n",
    "print(f\"Example content 1: '{actually_spam['cleaned_body'].iloc[3]}'\")\n",
    "print(f\"Example content 2: '{actually_spam['cleaned_body'].iloc[7]}'\")\n",
    "print(f\"Example content 3: '{actually_spam['cleaned_body'].iloc[8]}'\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "89282157",
   "metadata": {},
   "source": [
    "The following 3 email content are some example instances where the **baseline model correctly identified non-spam** but the alternative model misidentified.\n",
    "\n",
    "We observe that a common pattern these non-spam content has is that they happen to be quite instructive and invites the reader to take actions like clicking or opening a file which is similar to spam-typical content. However, these were innocent requests that may some times be shared amongst friends. Unfortunately, certain harmless non-spam content may coincidentally use words in a manner similar to malicious spam content which swayed the alternative model in the wrong direction during prediction."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "fdbd7094",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Example content 1: 'bill just wanted to let you know i was thinking of you today it was a long time ago when returnig from a shakedown patrol in the caribbean dave staton came down to the engine room lower level when my submarine pulled into new london telling me to get topside and to the hospital as my wife was having a baby i missed you being born by about hour but i was able to get there and hold you soon after you looked like winston churchill with a little turtle head your mom was exhausted but happy mke sure you give her a call today i know she misses talking to you love dad'\n",
      "Example content 2: 'in sigh here is esai s latest natural gas fundwatch edna o connell office manager esai edgewater place suite wakefield ma ednao esaibos com ngol pdf'\n",
      "Example content 3: 'i am sure doerfer never said that only binary comparison should be allowed e g turkic and mongolic but not turkic mongolic and manchu tungusic all at once on the contary what he said over and over again was that binary comparison would not prove the existence of genetic relationship for the whole group marcel erdal'\n"
     ]
    }
   ],
   "source": [
    "not_actually_spam = results_analysis_df[(results_analysis_df[\"label\"] == results_analysis_df[\"baseline_predict\"]) & (results_analysis_df[\"label\"] == 0)]\n",
    "print(f\"Example content 1: '{not_actually_spam['cleaned_body'].iloc[3]}'\")\n",
    "print(f\"Example content 2: '{not_actually_spam['cleaned_body'].iloc[6]}'\")\n",
    "print(f\"Example content 3: '{not_actually_spam['cleaned_body'].iloc[11]}'\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
